{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "from nameparser import HumanName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read bipartite graph and extract names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4054832"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bipartite_all = nx.read_gpickle(os.getcwd() + '/Pickle/bipartite-all010420.pickle')\n",
    "bipartite_all.number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes from *bipartite_all* have the following attributes:\n",
    "1. degree: int\n",
    "2. name: string\n",
    "3. is_trusted: bool\n",
    "4. is_employee: bool\n",
    "5. bipartite: int\n",
    "\n",
    "Access: bipartite_all.nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'degree': 17,\n",
       " 'name': 'JOSEPH GALLO',\n",
       " 'is_trustee': True,\n",
       " 'is_employee': True,\n",
       " 'bipartite': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bipartite_all.nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'JOSEPH GALLO'),\n",
       " (1, 'EMMA DUNCH'),\n",
       " (2, 'DONALD BORROR'),\n",
       " (3, 'LINDA MOFFITT'),\n",
       " (4, \"M'LISS DORRANCE\")]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bipartite_names = list(bipartite_all.nodes(data = 'name'))  # extract only names\n",
    "bipartite_names[: 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read LittleSis names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205548"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "littlesis_names = {}\n",
    "\n",
    "with open(os.getcwd() + '/Pickle/all_people.pickle', 'rb') as pkl:\n",
    "    littlesis_names = pickle.load(pkl)\n",
    "    \n",
    "len(littlesis_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Roland A Hernandez'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "littlesis_names['1024']  # key is an ent ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanNames(names_dict):\n",
    "    clean_names = {}\n",
    "    error_count, error_list = 0, []\n",
    "    \n",
    "    for name_id in names_dict:\n",
    "        try:\n",
    "            name = names_dict[name_id].strip().upper()\n",
    "\n",
    "            human_name = HumanName(name)\n",
    "\n",
    "            names_list = [human_name.first, human_name.middle, human_name.last]\n",
    "            names_list = [n for n in names_list if len(n) > 0]\n",
    "\n",
    "            if type(name_id) == str:  # convert string ent IDs to int\n",
    "                name_id = int(name_id)\n",
    "                \n",
    "            clean_names[name_id] = ' '.join(names_list)\n",
    "        \n",
    "        except:\n",
    "            error_count += 1\n",
    "            error_list.append(name_id)\n",
    "            \n",
    "#     print(error_count, error_list[: 3])\n",
    "    print(error_count)\n",
    "    return clean_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "clean_littlesis_names = cleanNames(littlesis_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ROLAND A HERNANDEZ'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_littlesis_names[1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "max_num = 1000  # max number of names from bipartite_all, change this value to change the size of the bipartite_all subset!\n",
    "# max_num = len(bipartite_names)  # select this to run for all names in bipartite-all\n",
    "bipartite_names_temp = {item[0]: item[1] for item in bipartite_names[: max_num] if item[1] is not None}  # create dict with ID:name for bipartite-all people if their name is not None, ID is the same as node ID in the nx object\n",
    "clean_bipartite_names = cleanNames(bipartite_names_temp)\n",
    "clean_bipartite_names_reverse = {clean_bipartite_names[i]: i for i in clean_bipartite_names}\n",
    "remaining_bipartite = len(clean_bipartite_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205548 740 740\n"
     ]
    }
   ],
   "source": [
    "print(len(clean_littlesis_names), len(clean_bipartite_names), len(clean_bipartite_names_reverse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting 100 out of 740\n",
      "Inserting 200 out of 740\n",
      "Inserting 300 out of 740\n",
      "Inserting 400 out of 740\n",
      "Inserting 500 out of 740\n",
      "Inserting 600 out of 740\n",
      "Inserting 700 out of 740\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "lsh = MinHashLSH(threshold = 0.5, num_perm = 128)\n",
    "\n",
    "for name_id in clean_bipartite_names:\n",
    "    count += 1\n",
    "    if count % 100 == 0:\n",
    "        print('Inserting', count, 'out of', remaining_bipartite)\n",
    "    \n",
    "    p = MinHash(num_perm = 128)\n",
    "    \n",
    "    name = clean_bipartite_names[name_id]\n",
    "    \n",
    "    for name_split in name.split():\n",
    "        p.update(name_split.encode('utf-8'))\n",
    "        \n",
    "    lsh.insert(name, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 740 names from bipartite-all\n"
     ]
    }
   ],
   "source": [
    "del clean_bipartite_names\n",
    "print('Inserted', count, 'names from bipartite-all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareNames(person1, person2):\n",
    "    same_person_flag = False\n",
    "    \n",
    "    if person1 != person2:\n",
    "        names1 = person1.split()\n",
    "        names2 = person2.split()\n",
    "        \n",
    "        common_names = list(set(names1) & set(names2))  # intersection\n",
    "        \n",
    "        # we need names of min len = 3 to be same\n",
    "        common_names_min_len = [n for n in common_names if len(n) >= 3]\n",
    "        \n",
    "        neither = None\n",
    "        \n",
    "        try:\n",
    "            if len(common_names_min_len) > 1:  # if at least 2 names satisfy min len condition\n",
    "                if len(common_names) == len(names1) or len(common_names) == len(names2):\n",
    "                    same_person_flag = True\n",
    "\n",
    "                elif (len(names1) - len(common_names) == 1 or len(names2) - len(common_names) == 1) and (len(names1) - len(common_names) <= 2 or len(names2) - len(common_names) <= 2) and names1[0] == names2[0] and names1[-1] == names2[-1]:\n",
    "                    neither = list(set(names1).union(set(names2)) - (set(names1) & set(names2)))  # neither i.e. complement = union - intersection\n",
    "\n",
    "                    if len(neither) == 2 and (len(neither[0]) == 1 or len(neither[1] == 1)) and neither[0][0] == neither[1][0]:\n",
    "                        same_person_flag = True\n",
    "\n",
    "        except:\n",
    "            print(neither, type(neither), person1)\n",
    "    \n",
    "    elif person1 == person2:\n",
    "        same_person_flag = True\n",
    "    \n",
    "    return same_person_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "matched_names = {}\n",
    "\n",
    "for name_id in clean_littlesis_names:  # for each name in littlesis data, find matches in the hash\n",
    "    count += 1\n",
    "    if count % 500 == 0:\n",
    "        print('Comparing', count)\n",
    "        \n",
    "    p = MinHash(num_perm = 128)\n",
    "    \n",
    "    name = clean_littlesis_names[name_id]\n",
    "    \n",
    "    for name_split in name.split():\n",
    "        p.update(name_split.encode('utf-8'))\n",
    "    \n",
    "    res = lsh.query(p)\n",
    "    \n",
    "    for bip_name in res:\n",
    "        same_person = compareNames(name, bip_name)\n",
    "        \n",
    "        if same_person:\n",
    "#             matched_names[name_id] = clean_bipartite_names_reverse[bip_name]\n",
    "            # handling multiple matches\n",
    "            if name_id in matched_names:\n",
    "                matched_names[name_id].append(clean_bipartite_names_reverse[bip_name])  # append if we've seen at least one match for name_id before\n",
    "            else:\n",
    "                matched_names[name_id] = [clean_bipartite_names_reverse[bip_name]]  # create a new list if it's the first match for name_id\n",
    "\n",
    "print(len(matched_names))\n",
    "\n",
    "with open(os.getcwd() + '/Pickle/matched_names.pickle', 'wb') as pkl:\n",
    "    pickle.dump(matched_names, pkl, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118659"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_names_res = {}\n",
    "\n",
    "with open(os.getcwd() + '/Pickle/matched_names.pickle', 'rb') as pkl:\n",
    "    matched_names_res = pickle.load(pkl)\n",
    "    \n",
    "len(matched_names_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[934460, 3191192]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_names_res[262150]  # key: LittleSis ent ID, value: list with node IDs from bipartite-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THOMAS ROONEY'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_littlesis_names[262150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THOMAS J ROONEY\n",
      "THOMAS M ROONEY\n"
     ]
    }
   ],
   "source": [
    "for i in matched_names_res[262150]:\n",
    "    print(bipartite_all.nodes[i]['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every key i.e. LittleSis name in matched_names, we need the filtered LittleSis relations for that key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1230815, 15)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels = pd.read_pickle(os.getcwd() + '/Pickle/all_rels.pkl')  # read LittleSis relationships\n",
    "rels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284500, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents = pd.read_pickle(os.getcwd() + '/Pickle/all_entities.pkl')  # read LittleSis entities\n",
    "ents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118659, 13)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_ents = ents[ents['id'].isin(matched_names_res.keys())]  # keep only those ents that appear in matched_names_res\n",
    "matched_ents.shape  # same len as matched_names_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy/Think Tank\n"
     ]
    }
   ],
   "source": [
    "type_val_counts = matched_ents.explode('types')['types'].value_counts()\n",
    "reqd_types = ['Philanthropy', 'Other Not-for-Profit', 'Academic Research Institute', 'School', 'Cultural/Arts', 'Policy/Think Tank']  # 'Academic' has been removed\n",
    "count = 0\n",
    "\n",
    "for i in type_val_counts.index:\n",
    "    if i in reqd_types:\n",
    "        print(i)\n",
    "        count += 1\n",
    "        \n",
    "if count == 0:\n",
    "    print('None present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>extensions</th>\n",
       "      <th>website</th>\n",
       "      <th>name</th>\n",
       "      <th>primary_ext</th>\n",
       "      <th>aliases</th>\n",
       "      <th>blurb</th>\n",
       "      <th>types</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339139</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Person': {'name_nick': None, 'nationality': ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Nicole Theis</td>\n",
       "      <td>Person</td>\n",
       "      <td>[Nicole Theis]</td>\n",
       "      <td>founder and president of the Delaware Family ...</td>\n",
       "      <td>[Person, Lobbyist, Lobbying Firm, Policy/Think...</td>\n",
       "      <td>2019-02-12T21:10:10Z</td>\n",
       "      <td>339139</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       summary  parent_id                                         extensions  \\\n",
       "339139    None        NaN  {'Person': {'name_nick': None, 'nationality': ...   \n",
       "\n",
       "       website          name primary_ext         aliases  \\\n",
       "339139    None  Nicole Theis      Person  [Nicole Theis]   \n",
       "\n",
       "                                                    blurb  \\\n",
       "339139   founder and president of the Delaware Family ...   \n",
       "\n",
       "                                                    types  \\\n",
       "339139  [Person, Lobbyist, Lobbying Firm, Policy/Think...   \n",
       "\n",
       "                  updated_at      id start_date end_date  \n",
       "339139  2019-02-12T21:10:10Z  339139       None     None  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filterByType(df):  # returns indices of rows that satisfy the filter by 'type' criterion\n",
    "    \n",
    "    df_exploded = df.explode('types')\n",
    "    \n",
    "    return df_exploded[df_exploded['types'].isin(reqd_types)].index\n",
    "\n",
    "index_to_keep = filterByType(matched_ents)\n",
    "filtered_ents = ents.loc[index_to_keep]\n",
    "filtered_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(861244, 15)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_rels = rels[rels['entity1_id'].isin(matched_ents['id']) | rels['entity2_id'].isin(matched_ents['id'])]  # keep only relationships where at least one node appears in matched_ents\n",
    "matched_rels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtlasView({6950337: {}})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bipartite_all[2600811] # len = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'degree': 2,\n",
       " 'name': 'JAMES GOLDSTON',\n",
       " 'is_trustee': True,\n",
       " 'is_employee': True,\n",
       " 'bipartite': 1}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bipartite_all.nodes[1295776]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ALTUS GLOBAL ALLIANCE'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bipartite_all.nodes[6950337]['Uppername']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118659"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_res_counter = {i: {j: 0 for j in matched_names_res[i]} for i in matched_names_res}  # {littlesis id: {bipartite-all id: 0, ...}, ...}\n",
    "len(matched_res_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{262162: {1295776: 0, 2600811: 0}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_d = {262162: {1295776: 0, 2600811: 0}}\n",
    "temp_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = matched_rels[matched_rels['entity1_id'].isin([262162]) | matched_rels['entity2_id'].isin([262162])]\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = x[x['entity1_id'] != 262162]['entity1_id'].append(x[x['entity2_id'] != 262162]['entity2_id'])\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ents[ents['id'].isin(y)][['name', 'id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SAVING GRACE ANIMALS FOR ADOPTION INC', 'OPEN SOCIETY INSTITUTE']\n",
      "['ALTUS GLOBAL ALLIANCE']\n",
      "           name     id\n",
      "86189  ABC News  86189\n"
     ]
    }
   ],
   "source": [
    "def counting_rels():  # compare LittleSis relations with bipartite-all relations\n",
    "    for ent_id in temp_d:\n",
    "        relations = matched_rels[matched_rels['entity1_id'].isin([ent_id]) | matched_rels['entity2_id'].isin([ent_id])]\n",
    "        related_ents_id = relations[relations['entity1_id'] != ent_id]['entity1_id'].append(relations[relations['entity2_id'] != ent_id]['entity2_id'])\n",
    "        related_ents = ents[ents['id'].isin(related_ents_id)][['name', 'id']]\n",
    "        \n",
    "        for bip_match in temp_d[ent_id]:\n",
    "            names = [bipartite_all.nodes[i]['Uppername'] for i in bipartite_all[bip_match]]\n",
    "            print(names)\n",
    "            \n",
    "            # compare names with related_ents['name']\n",
    "            \n",
    "            \n",
    "        \n",
    "#     print(related_ents)\n",
    "counting_rels()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
