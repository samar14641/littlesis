{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "from nameparser import HumanName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read bipartite graph and extract names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4054832"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bipartite_all = nx.read_gpickle(os.getcwd() + '/Pickle/bipartite-all010420.pickle')\n",
    "bipartite_all.number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes from *bipartite_all* have the following attributes:\n",
    "1. degree: int\n",
    "2. name: string\n",
    "3. is_trusted: bool\n",
    "4. is_employee: bool\n",
    "5. bipartite: int\n",
    "\n",
    "Access: bipartite_all.nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'degree': 17,\n",
       " 'name': 'JOSEPH GALLO',\n",
       " 'is_trustee': True,\n",
       " 'is_employee': True,\n",
       " 'bipartite': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bipartite_all.nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'JOSEPH GALLO'),\n",
       " (1, 'EMMA DUNCH'),\n",
       " (2, 'DONALD BORROR'),\n",
       " (3, 'LINDA MOFFITT'),\n",
       " (4, \"M'LISS DORRANCE\")]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bipartite_names = list(bipartite_all.nodes(data = 'name'))  # extract only names\n",
    "bipartite_names[: 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read LittleSis names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205548"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "littlesis_names = {}\n",
    "\n",
    "with open(os.getcwd() + '/Pickle/all_people.pickle', 'rb') as pkl:\n",
    "    littlesis_names = pickle.load(pkl)\n",
    "    \n",
    "len(littlesis_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Roland A Hernandez'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "littlesis_names['1024']  # key is an ent ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanNames(names_dict):\n",
    "    clean_names = {}\n",
    "    error_count, error_list = 0, []\n",
    "    \n",
    "    for name_id in names_dict:\n",
    "        try:\n",
    "            name = names_dict[name_id].strip().upper()\n",
    "\n",
    "            human_name = HumanName(name)\n",
    "\n",
    "            names_list = [human_name.first, human_name.middle, human_name.last]\n",
    "            names_list = [n for n in names_list if len(n) > 0]\n",
    "\n",
    "            if type(name_id) == str:  # convert string ent IDs to int\n",
    "                name_id = int(name_id)\n",
    "                \n",
    "            clean_names[name_id] = ' '.join(names_list)\n",
    "        \n",
    "        except:\n",
    "            error_count += 1\n",
    "            error_list.append(name_id)\n",
    "            \n",
    "#     print(error_count, error_list[: 3])\n",
    "    print(error_count)\n",
    "    return clean_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "clean_littlesis_names = cleanNames(littlesis_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ROLAND A HERNANDEZ'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_littlesis_names[1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "max_num = 1000  # max number of names from bipartite_all, change this value to change the size of the bipartite_all subset!\n",
    "bipartite_names_temp = {item[0]: item[1] for item in bipartite_names[: max_num] if item[1] is not None}\n",
    "clean_bipartite_names = cleanNames(bipartite_names_temp)\n",
    "remaining_bipartite = len(clean_bipartite_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205548 740\n"
     ]
    }
   ],
   "source": [
    "print(len(clean_littlesis_names), len(clean_bipartite_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting 0 out of 740\n",
      "Inserting 100 out of 740\n",
      "Inserting 200 out of 740\n",
      "Inserting 300 out of 740\n",
      "Inserting 400 out of 740\n",
      "Inserting 500 out of 740\n",
      "Inserting 600 out of 740\n",
      "Inserting 700 out of 740\n"
     ]
    }
   ],
   "source": [
    "lsh = MinHashLSH(threshold = 0.5, num_perm = 128)\n",
    "\n",
    "for i, name in enumerate(clean_bipartite_names):\n",
    "    if i % 100 == 0:\n",
    "        print('Inserting', i, 'out of', remaining_bipartite)\n",
    "    \n",
    "    p = MinHash(num_perm = 128)\n",
    "    \n",
    "    for name_split in name.split():\n",
    "        p.update(name_split.encode('utf-8'))\n",
    "        \n",
    "    lsh.insert(name, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareNames(person1, person2):\n",
    "    same_person_flag = False\n",
    "    \n",
    "    if person1 != person2:\n",
    "        names1 = person1.split()\n",
    "        names2 = person2.split()\n",
    "        \n",
    "        common_names = list(set(names1) & set(names2))  # intersection\n",
    "        \n",
    "        # we need names of min len = 3 to be same\n",
    "        common_names_min_len = [n for n in common_names if len(n) >= 3]\n",
    "        \n",
    "        if len(common_names_min_len) > 1:  # if at least 2 names satisfy min len condition\n",
    "            if len(common_names) == len(names1) or len(common_names) == len(names2):\n",
    "                same_person_flag = True\n",
    "            \n",
    "            elif (len(names1) - len(common_names) == 1 or len(names2) - len(common_names) == 1) and (len(names1) - len(common_names) <= 2 or len(names2) - len(common_names) <= 2) and names1[0] == names2[0] and names1[-1] == names2[-1]:\n",
    "                neither = list(set(names1).union(set(names2)) - (set(names1) & set(names2)))  # neither i.e. complement = union - intersection\n",
    "                \n",
    "                if len(neither) == 2 and (len(neither[0]) == 1 or len(neither[1] == 1)) and neither[0][0] == neither[1][0]:\n",
    "                    same_person_flag = True\n",
    "    \n",
    "    return same_person_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205548 740\n"
     ]
    }
   ],
   "source": [
    "clean_littlesis_names_id = {num: n for num, n in enumerate(clean_littlesis_names)}  # the number should be the key as the names don't \n",
    "clean_bipartite_names_id = {num: n for num, n in enumerate(clean_bipartite_names)}\n",
    "print(len(clean_littlesis_names_id), len(clean_bipartite_names_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing 0\n",
      "Comparing 100\n",
      "Comparing 200\n",
      "Comparing 300\n",
      "Comparing 400\n",
      "Comparing 500\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'JOSHUA SMITH'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-b35ef1e491b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msame_person\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mmatched_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclean_littlesis_names_id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_bipartite_names_id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbip_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatched_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'JOSHUA SMITH'"
     ]
    }
   ],
   "source": [
    "matched_names = {}\n",
    "\n",
    "for i, name in enumerate(clean_littlesis_names):  # for each name in littlesis data, find matches in the hash\n",
    "    if i % 100 == 0:\n",
    "        print('Comparing', i)\n",
    "        \n",
    "    p = MinHash(num_perm = 128)\n",
    "    \n",
    "    for name_split in name.split():\n",
    "        p.update(name_split.encode('utf-8'))\n",
    "    \n",
    "    res = lsh.query(p)\n",
    "    \n",
    "    for bip_name in res:\n",
    "        same_person = compareNames(name, bip_name)\n",
    "        \n",
    "        if same_person:\n",
    "            matched_names[clean_littlesis_names_id[i]] = clean_bipartite_names_id[bip_name]\n",
    "\n",
    "print(len(matched_names))\n",
    "\n",
    "# with open(os.getcwd() + '/Pickle/matched_names.pickle', 'wb') as pkl:\n",
    "#     pickle.dump(matched_names, pkl, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
